{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbX4QXYsu7QE",
        "colab_type": "text"
      },
      "source": [
        "# 日本語解析の共通処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLXnBQxBut7j",
        "colab_type": "text"
      },
      "source": [
        "## MeCabのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faWZ8zKkuTCH",
        "colab_type": "code",
        "outputId": "9aff191d-dd26-4bdc-b80e-d0da64c646db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5561
        }
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n",
            "  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n",
            "  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "Suggested packages:\n",
            "  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n",
            "  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n",
            "  libwww-perl xapian-tools\n",
            "The following NEW packages will be installed:\n",
            "  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n",
            "  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n",
            "  libhttp-message-perl libio-html-perl libio-string-perl\n",
            "  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n",
            "  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n",
            "0 upgraded, 21 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 3,877 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n",
            "Fetched 3,877 kB in 2s (2,085 kB/s)\n",
            "Selecting previously unselected package aptitude-common.\n",
            "(Reading database ... 130812 files and directories currently installed.)\n",
            "Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n",
            "Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n",
            "Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n",
            "Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libcwidget3v5:amd64.\n",
            "Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n",
            "Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Selecting previously unselected package libxapian30:amd64.\n",
            "Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Selecting previously unselected package aptitude.\n",
            "Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n",
            "Unpacking aptitude (0.8.10-6ubuntu1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libsub-name-perl.\n",
            "Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n",
            "Unpacking libsub-name-perl (0.21-1build1) ...\n",
            "Selecting previously unselected package libclass-accessor-perl.\n",
            "Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n",
            "Unpacking libclass-accessor-perl (0.51-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libio-string-perl.\n",
            "Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n",
            "Unpacking libio-string-perl (1.08-3) ...\n",
            "Selecting previously unselected package libparse-debianchangelog-perl.\n",
            "Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n",
            "Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up aptitude-common (0.8.10-6ubuntu1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up libio-string-perl (1.08-3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libsub-name-perl (0.21-1build1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n",
            "Setting up libclass-accessor-perl (0.51-1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n",
            "Setting up aptitude (0.8.10-6ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "The following NEW packages will be installed:\n",
            "  libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n",
            "The following packages will be REMOVED:\n",
            "  libnvidia-common-410{u} \n",
            "0 packages upgraded, 8 newly installed, 1 to remove and 11 not upgraded.\n",
            "Need to get 29.0 MB of archives. After unpacking 277 MB will be used.\n",
            "Get: 1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get: 2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get: 3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Fetched 29.0 MB in 3s (10.1 MB/s)\n",
            "(Reading database ... 131271 files and directories currently installed.)\n",
            "Removing libnvidia-common-410 (410.104-0ubuntu1) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "(Reading database ... 131266 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../1-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../2-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../3-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../4-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../5-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../6-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../7-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "                            \n",
            "Collecting mecab-python3==0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/e9/bbf5fc790a2bedd96fbaf47a84afa060bfb0b3e0217e5f64b32bd4bbad69/mecab-python3-0.7.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-python3\n",
            "  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/07/3a/5f22ccc9f381f3bc01fa023202061cd1e0e9af855292f005dd\n",
            "Successfully built mecab-python3\n",
            "Installing collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQC5RVGPvzdM",
        "colab_type": "text"
      },
      "source": [
        "## 文書から単語を抽出\n",
        "\n",
        "今回は使い勝手のために、文書を直接コードに記載している。  \n",
        "実際にはファイルから読み込むなどの手法を使用することになる。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Czi-4A5eGKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習に使用するデータ\n",
        "# [(タイトル), (文書)]の構造がリストになっている\n",
        "docs_train = [\n",
        "['うどん', \n",
        "'うどんは、小麦粉を練って長く切った、ある程度の幅と太さを持つ麺またはその料理であり、\\\n",
        "主に日本で食されているものを指すが、過去の日本の移民政策の影響や食のグローバル化の影響により、\\\n",
        "関係各国にも近似な料理が散見される。\\\n",
        "饂飩とも書く。\\\n",
        "細い物などは「冷麦」「素麺」と分けて称することが一般的ではあるが、\\\n",
        "乾麺に関して太さによる規定がある以外は厳密な規定はなく、細い麺であっても「稲庭うどん」の例も存在し、\\\n",
        "厚みの薄い麺も基準を満たせば、乾麺については「きしめん、ひもかわ」と称してよいと規定があり、\\\n",
        "これらもうどんの一種類に含まれる。'],\n",
        "['おにぎり', \n",
        "'おにぎり（御握り）は、ご飯を三角形・俵形・球状などに加圧成型した食べ物である。\\\n",
        "通常は手のひらに載る程度の大きさに作る。「おむすび」や「握り飯」とも呼ばれる。\\\n",
        "保存性・携行性に優れており、手づかみで食べられることから、日本で古くから今日に至るまで携行食や弁当として重宝されている。\\\n",
        "元々は残り飯の保存や携行食として発達したが、その後は常食としてのおにぎりが主流となり、\\\n",
        "現代ではコンビニエンスストアやスーパーマーケットでも販売されている。\\\n",
        "携行する必要がない居酒屋や定食屋でも提供されるほど、日本の食文化に定着している。\\\n",
        "日本のコンビニエンスストアや外食・中食店の海外進出、日本滞在経験を持つ外国人の増加に伴い、\\\n",
        "世界各国でおにぎりが販売されるようになっている。']\n",
        "]\n",
        "\n",
        "# テストに使用するデータ\n",
        "# 上記の学習に使用するデータの中から、このデータに類似したものを探す\n",
        "doc_test = [\n",
        "['そうめん', \n",
        "'素麺（索麺、そうめん）は、小麦粉を原料とした日本および東アジアの麺のひとつ。\\\n",
        "主に乾麺として流通するため、市場で通年入手できるが、冷やして食することが多く、\\\n",
        "清涼感を求めて夏の麺料理として食するのが一般的である。']\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNfVoKhxwMF_",
        "colab_type": "code",
        "outputId": "71a8b614-195e-4d1c-c127-bf5375c1c0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import MeCab\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# MeCabインスタンスを生成\n",
        "# 単語分解した際の出力フォーマットを\"chasen\"形式にする\n",
        "mecab = MeCab.Tagger(\"-Ochasen\")\n",
        "\n",
        "# docs_trainのタイトルと、文書から抽出した単語一覧のTaggedDocument型リスト\n",
        "title_words_lists = []\n",
        "\n",
        "# doc_testのタイトルと、文書から抽出した単語一覧のTaggedDocument型リスト\n",
        "title_words_lists_test = []\n",
        "\n",
        "# 文書に含まれる単語を抽出する関数\n",
        "# 引数には文字列型を指定する\n",
        "def extractWords(content):\n",
        "  # 文章から抽出した単語の一覧\n",
        "  words = []\n",
        "\n",
        "  # 文章を単語に分解(単語ごとに1行の分解結果が出力される)\n",
        "  lines = mecab.parse(content).splitlines()\n",
        "  for line in lines:\n",
        "    chunks = line.split('\\t') # 分解結果の項目はタブで区切られている\n",
        "    # TODO: 抽出する品詞は要調整\n",
        "    # 分解結果を確認し、動詞・形容詞・名詞(数を除く)のみ抽出\n",
        "    if len(chunks) > 3 \\\n",
        "        and (chunks[3].startswith('動詞') or chunks[3].startswith('形容詞') \\\n",
        "             or (chunks[3].startswith('名詞') and not chunks[3].startswith('名詞-数'))):\n",
        "      words.append(chunks[0])\n",
        "  return words\n",
        "\n",
        "\n",
        "print('===単語抽出実施(学習データ)===')\n",
        "for doc in docs_train:\n",
        "  title = doc[0]\n",
        "  content = doc[1]\n",
        "\n",
        "  # 文章から単語を抽出\n",
        "  words = extractWords(content)\n",
        "  # タイトルと、そこから抽出した単語一覧をセットにして登録\n",
        "  title_words_lists.append(TaggedDocument(words=words, tags=[title]))\n",
        "  \n",
        "  # 単語一覧を出力\n",
        "  print(title, words)\n",
        "\n",
        "print('===単語抽出実施(テストデータ)===')\n",
        "for doc in doc_test:\n",
        "  title = doc[0]\n",
        "  content = doc[1]\n",
        "\n",
        "  # 文章から単語を抽出\n",
        "  words = extractWords(content)\n",
        "  # タイトルと、そこから抽出した単語一覧をセットにして登録\n",
        "  title_words_lists_test.append(TaggedDocument(words=words, tags=[title]))\n",
        "  \n",
        "  # 単語一覧を出力\n",
        "  print(title, words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===単語抽出実施(学習データ)===\n",
            "うどん ['うどん', '小麦粉', '練っ', '長く', '切っ', '幅', '太', 'さ', '持つ', '麺', '料理', '主', '日本', '食', 'さ', 'れ', 'いる', 'もの', '指す', '過去', '日本', '移民', '政策', '影響', '食', 'グローバル', '化', '影響', '関係', '各国', '近似', '料理', '散見', 'さ', 'れる', '饂飩', '書く', '細い', '物', '冷麦', '素麺', '分け', '称する', 'こと', '一般', '的', 'ある', '乾麺', '太', 'さ', '規定', 'ある', '以外', '厳密', '規定', '細い', '麺', '稲庭', 'うどん', '例', '存在', 'し', '厚み', '薄い', '麺', '基準', '満たせ', '乾麺', 'きし', 'めん', 'ひも', '称し', 'よい', '規定', 'あり', 'これら', 'うどん', '種類', '含ま', 'れる']\n",
            "おにぎり ['おにぎり', '握り', 'ご飯', '三角形', '俵', '形', '球状', '加', '圧', '成型', 'し', '食べ物', '通常', '手のひら', '載る', '程度', '大き', 'さ', '作る', 'おむすび', '握り飯', '呼ば', 'れる', '保存', '性', '携行', '性', '優れ', 'おり', '手づかみ', '食べ', 'られる', 'こと', '日本', '今日', '至る', '携行', '食', '弁当', '重宝', 'さ', 'れ', 'いる', '残り', '飯', '保存', '携行', '食', '発達', 'し', 'その後', '常食', 'おにぎり', '主流', 'なり', '現代', 'コンビニエンスストア', 'スーパーマーケット', '販売', 'さ', 'れ', 'いる', '携行', 'する', '必要', 'ない', '居酒屋', '定食', '屋', '提供', 'さ', 'れる', 'ほど', '日本', '食', '文化', '定着', 'し', 'いる', '日本', 'コンビニエンスストア', '外食', '中食', '店', '海外', '進出', '日本', '滞在', '経験', '持つ', '外国', '人', '増加', '伴い', '世界', '各国', 'おにぎり', '販売', 'さ', 'れる', 'よう', 'なっ', 'いる']\n",
            "===単語抽出実施(テストデータ)===\n",
            "そうめん ['素麺', '索麺', 'めん', '小麦粉', '原料', 'し', '日本', '東アジア', '麺', 'ひとつ', '主', '乾麺', '流通', 'する', 'ため', '市場', '通年', '入手', 'できる', '冷やし', '食する', 'こと', '多く', '清涼', '感', '求め', '夏', '麺', '料理', '食する', 'の', '一般', '的']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-0xvqmGJKGp",
        "colab_type": "text"
      },
      "source": [
        "## 単語抽出結果の確認と精度改善"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5dZbA1HE3o",
        "colab_type": "text"
      },
      "source": [
        "単語抽出結果から、単語が期待するように分割されているかを確認する。  \n",
        "Mecab辞書をカスタマイズすることで、単語分割の精度できる可能性がある。  \n",
        "\n",
        "MeCab: 単語の追加方法  \n",
        "https://taku910.github.io/mecab/dic.html\n",
        "\n",
        "また、使用している辞書についても、上記の例ではmecab-ipadicを使用しているが、  \n",
        "mecab-ipadic-neologdという辞書もあり、こちらの方が新語に強いと言われている。\n",
        "\n",
        "https://github.com/neologd/mecab-ipadic-neologd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApfNp6M-xhhK",
        "colab_type": "text"
      },
      "source": [
        "# 分析方法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CksPm4Okxxib",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n",
        "単語の出現回数に着目し、その文章の「特徴」となる単語をスコア付けする方法。  \n",
        "「特徴」となる単語が共通している文書は似ていると推測される。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWrSS2Lbxskf",
        "colab_type": "code",
        "outputId": "effe1ab8-a65c-480a-fc4e-f0a86076ea7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2789
        }
      },
      "source": [
        "# 学習用データ、テスト用データの両方について、各単語のTF-IDF値を算出\n",
        "\n",
        "from gensim import corpora\n",
        "from gensim import models\n",
        "from operator import itemgetter\n",
        "\n",
        "# 学習データから抽出したすべての単語を集約したリストを作成\n",
        "all_words = []\n",
        "for title_words in title_words_lists:\n",
        "  all_words.append(title_words.words)\n",
        "\n",
        "# 単語をID化し重複を除外した辞書を作成\n",
        "dictionary = corpora.Dictionary(all_words)\n",
        "\n",
        "# 辞書にテストデータの単語を追加\n",
        "for title_words in title_words_lists_test:\n",
        "  all_words.append(title_words.words)\n",
        "dictionary.add_documents(all_words)\n",
        "\n",
        "# 文章ごとに含まれる単語IDの個数を算出\n",
        "corpus = list(map(dictionary.doc2bow,all_words))\n",
        "\n",
        "# TF-IDFモデルの生成\n",
        "test_model = models.TfidfModel(corpus)\n",
        "\n",
        "# 文章に含まれる各単語についてTF-IDF値を算出\n",
        "corpus_tfidf = test_model[corpus]\n",
        "\n",
        "print('===TF-IDF値表示===')\n",
        "all_lists = title_words_lists + title_words_lists_test\n",
        "for (title_words, vector) in zip(all_lists, corpus_tfidf):\n",
        "  print(title_words.tags) # タイトルを出力\n",
        "  \n",
        "  # TF-IDF値の大きい順に単語を並べ替え\n",
        "  sorted_vector = sorted(vector, key=itemgetter(1), reverse=True)\n",
        "\n",
        "  # sorted_vectorは[(単語ID), (TF-IDF値)]のリストとなっているため、単語IDを単語に戻す\n",
        "  for word_tfidf in sorted_vector:\n",
        "    print('  {0}: {1}'.format(dictionary[word_tfidf[0]], word_tfidf[1]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===TF-IDF値表示===\n",
            "['うどん']\n",
            "  うどん: 0.3397988898947734\n",
            "  規定: 0.3397988898947734\n",
            "  ある: 0.22653259326318226\n",
            "  太: 0.22653259326318226\n",
            "  影響: 0.22653259326318226\n",
            "  細い: 0.22653259326318226\n",
            "  さ: 0.16721288003947896\n",
            "  麺: 0.1254096600296092\n",
            "  あり: 0.11326629663159113\n",
            "  きし: 0.11326629663159113\n",
            "  これら: 0.11326629663159113\n",
            "  ひも: 0.11326629663159113\n",
            "  もの: 0.11326629663159113\n",
            "  よい: 0.11326629663159113\n",
            "  グローバル: 0.11326629663159113\n",
            "  以外: 0.11326629663159113\n",
            "  例: 0.11326629663159113\n",
            "  冷麦: 0.11326629663159113\n",
            "  分け: 0.11326629663159113\n",
            "  切っ: 0.11326629663159113\n",
            "  化: 0.11326629663159113\n",
            "  厚み: 0.11326629663159113\n",
            "  厳密: 0.11326629663159113\n",
            "  含ま: 0.11326629663159113\n",
            "  基準: 0.11326629663159113\n",
            "  存在: 0.11326629663159113\n",
            "  幅: 0.11326629663159113\n",
            "  指す: 0.11326629663159113\n",
            "  政策: 0.11326629663159113\n",
            "  散見: 0.11326629663159113\n",
            "  書く: 0.11326629663159113\n",
            "  満たせ: 0.11326629663159113\n",
            "  物: 0.11326629663159113\n",
            "  称し: 0.11326629663159113\n",
            "  称する: 0.11326629663159113\n",
            "  移民: 0.11326629663159113\n",
            "  種類: 0.11326629663159113\n",
            "  稲庭: 0.11326629663159113\n",
            "  練っ: 0.11326629663159113\n",
            "  薄い: 0.11326629663159113\n",
            "  近似: 0.11326629663159113\n",
            "  過去: 0.11326629663159113\n",
            "  長く: 0.11326629663159113\n",
            "  関係: 0.11326629663159113\n",
            "  饂飩: 0.11326629663159113\n",
            "  れる: 0.08360644001973948\n",
            "  乾麺: 0.08360644001973948\n",
            "  料理: 0.08360644001973948\n",
            "  食: 0.08360644001973948\n",
            "  いる: 0.04180322000986974\n",
            "  めん: 0.04180322000986974\n",
            "  れ: 0.04180322000986974\n",
            "  一般: 0.04180322000986974\n",
            "  主: 0.04180322000986974\n",
            "  各国: 0.04180322000986974\n",
            "  小麦粉: 0.04180322000986974\n",
            "  持つ: 0.04180322000986974\n",
            "  的: 0.04180322000986974\n",
            "  素麺: 0.04180322000986974\n",
            "['おにぎり']\n",
            "  携行: 0.38140228953407734\n",
            "  おにぎり: 0.28605171715055805\n",
            "  コンビニエンスストア: 0.19070114476703867\n",
            "  保存: 0.19070114476703867\n",
            "  性: 0.19070114476703867\n",
            "  販売: 0.19070114476703867\n",
            "  さ: 0.17595529623344033\n",
            "  いる: 0.14076423698675228\n",
            "  れる: 0.10557317774006421\n",
            "  食: 0.10557317774006421\n",
            "  おむすび: 0.09535057238351934\n",
            "  おり: 0.09535057238351934\n",
            "  ご飯: 0.09535057238351934\n",
            "  その後: 0.09535057238351934\n",
            "  ない: 0.09535057238351934\n",
            "  なっ: 0.09535057238351934\n",
            "  なり: 0.09535057238351934\n",
            "  ほど: 0.09535057238351934\n",
            "  よう: 0.09535057238351934\n",
            "  られる: 0.09535057238351934\n",
            "  スーパーマーケット: 0.09535057238351934\n",
            "  三角形: 0.09535057238351934\n",
            "  世界: 0.09535057238351934\n",
            "  中食: 0.09535057238351934\n",
            "  主流: 0.09535057238351934\n",
            "  人: 0.09535057238351934\n",
            "  今日: 0.09535057238351934\n",
            "  伴い: 0.09535057238351934\n",
            "  作る: 0.09535057238351934\n",
            "  俵: 0.09535057238351934\n",
            "  優れ: 0.09535057238351934\n",
            "  加: 0.09535057238351934\n",
            "  呼ば: 0.09535057238351934\n",
            "  圧: 0.09535057238351934\n",
            "  増加: 0.09535057238351934\n",
            "  外国: 0.09535057238351934\n",
            "  外食: 0.09535057238351934\n",
            "  大き: 0.09535057238351934\n",
            "  定着: 0.09535057238351934\n",
            "  定食: 0.09535057238351934\n",
            "  居酒屋: 0.09535057238351934\n",
            "  屋: 0.09535057238351934\n",
            "  常食: 0.09535057238351934\n",
            "  店: 0.09535057238351934\n",
            "  弁当: 0.09535057238351934\n",
            "  形: 0.09535057238351934\n",
            "  必要: 0.09535057238351934\n",
            "  成型: 0.09535057238351934\n",
            "  手づかみ: 0.09535057238351934\n",
            "  手のひら: 0.09535057238351934\n",
            "  提供: 0.09535057238351934\n",
            "  握り: 0.09535057238351934\n",
            "  握り飯: 0.09535057238351934\n",
            "  文化: 0.09535057238351934\n",
            "  残り: 0.09535057238351934\n",
            "  海外: 0.09535057238351934\n",
            "  滞在: 0.09535057238351934\n",
            "  現代: 0.09535057238351934\n",
            "  球状: 0.09535057238351934\n",
            "  発達: 0.09535057238351934\n",
            "  程度: 0.09535057238351934\n",
            "  経験: 0.09535057238351934\n",
            "  至る: 0.09535057238351934\n",
            "  載る: 0.09535057238351934\n",
            "  通常: 0.09535057238351934\n",
            "  進出: 0.09535057238351934\n",
            "  重宝: 0.09535057238351934\n",
            "  食べ: 0.09535057238351934\n",
            "  食べ物: 0.09535057238351934\n",
            "  飯: 0.09535057238351934\n",
            "  れ: 0.07038211849337614\n",
            "  各国: 0.03519105924668807\n",
            "  持つ: 0.03519105924668807\n",
            "  する: 0.03519105924668807\n",
            "['そうめん']\n",
            "  食する: 0.41912268328500385\n",
            "  ため: 0.20956134164250192\n",
            "  できる: 0.20956134164250192\n",
            "  の: 0.20956134164250192\n",
            "  ひとつ: 0.20956134164250192\n",
            "  入手: 0.20956134164250192\n",
            "  冷やし: 0.20956134164250192\n",
            "  原料: 0.20956134164250192\n",
            "  夏: 0.20956134164250192\n",
            "  多く: 0.20956134164250192\n",
            "  市場: 0.20956134164250192\n",
            "  感: 0.20956134164250192\n",
            "  東アジア: 0.20956134164250192\n",
            "  求め: 0.20956134164250192\n",
            "  流通: 0.20956134164250192\n",
            "  清涼: 0.20956134164250192\n",
            "  索麺: 0.20956134164250192\n",
            "  通年: 0.20956134164250192\n",
            "  麺: 0.15468571200378836\n",
            "  めん: 0.07734285600189418\n",
            "  一般: 0.07734285600189418\n",
            "  主: 0.07734285600189418\n",
            "  乾麺: 0.07734285600189418\n",
            "  小麦粉: 0.07734285600189418\n",
            "  料理: 0.07734285600189418\n",
            "  的: 0.07734285600189418\n",
            "  素麺: 0.07734285600189418\n",
            "  する: 0.07734285600189418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4iK8SqdTCi6",
        "colab_type": "code",
        "outputId": "029a0cee-639a-49bc-e6a4-901fe962ad76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# 学習用データの中から、テスト用データに類似するものを検索\n",
        "\n",
        "# テストデータのTF-IDF値を取得(テストデータはリストの末尾)\n",
        "test_vector = corpus_tfidf[len(corpus_tfidf)-1]\n",
        "\n",
        "# TF-IDF値の大きい順に単語を並び変え\n",
        "test_vector_sorted = sorted(vector, key=itemgetter(1), reverse=True)\n",
        "\n",
        "# テスト用データに含まれる単語が他の文書に存在するか確認\n",
        "print('===テストデータと同一の単語を含む文書===')\n",
        "print('単語(テストデータ文書でのTF-IDF値): 単語を含む文書タイトル(その文書でのTF-IDF値) ...')\n",
        "print('------')\n",
        "for test in test_vector_sorted:\n",
        "  print_str = '' # 結果表示用\n",
        "  for i, target in enumerate(corpus_tfidf):\n",
        "    # corpus_tfidfの末尾はテストデータ自身なので、確認はその前まで\n",
        "    if i == len(corpus_tfidf)-1:\n",
        "      break;\n",
        "    for target_word in target:\n",
        "      if test[0] == target_word[0]:\n",
        "        print_str += ' {0}({1})'.format(title_words_lists[i].tags, target_word[1])\n",
        "  if print_str != '':\n",
        "    print('{0}({1}):{2}'.format(dictionary[test[0]], test[1], print_str)) # test[0]は単語IDのため、単語に変換"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===テストデータと同一の単語を含む文書===\n",
            "単語(テストデータ文書でのTF-IDF値): 単語を含む文書タイトル(その文書でのTF-IDF値) ...\n",
            "------\n",
            "麺(0.15468571200378836): ['うどん'](0.1254096600296092)\n",
            "めん(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "一般(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "主(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "乾麺(0.07734285600189418): ['うどん'](0.08360644001973948)\n",
            "小麦粉(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "料理(0.07734285600189418): ['うどん'](0.08360644001973948)\n",
            "的(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "素麺(0.07734285600189418): ['うどん'](0.04180322000986974)\n",
            "する(0.07734285600189418): ['おにぎり'](0.03519105924668807)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd8NBX66aTyX",
        "colab_type": "text"
      },
      "source": [
        "TF-IDFは単語の出現回数から統計的に算出されるものであるため、調整する仕組みはない。  \n",
        "もし調整をするのであれば、特定の単語に対してTF-IDF値を増減するテーブルを作成する程度。  \n",
        "\n",
        "また、類似度の表現方法について、上記では単語が一致するかどうかで見ているが、  \n",
        "さらに一致した単語のTF-IDF値などを使ってスコア化すると、どの文書が似ているかがわかりやすくなる。  \n",
        "※ただし、どの観点で似ているかが見えにくくなることには注意すべき。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k72BsYEVzfHt",
        "colab_type": "text"
      },
      "source": [
        "## Doc2Vec \n",
        "文書を多次元のベクトル値に変換する方法。  \n",
        "ベクトルの距離で類似度を算出できる他にも、足し算や引き算を行うことができる。  \n",
        "※A文書とB文書の、両方の要素を持っている文書は？ といった具合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwhOAhAs1Aiv",
        "colab_type": "code",
        "outputId": "9acf1b1a-e30f-49e6-9c6b-8786d9d97416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "# 学習実行。引数の意味は以下の通り。(適宜調整する必要がある)\n",
        "#  documents: 文書のタグと単語リストがセットになったもの(TaggedDocument)のリスト \n",
        "#  vector_size:  文書ベクトルの次元数\n",
        "#  window:  指定した個数分の、隣接する単語を使って学習を行う\n",
        "#  min_count: 単語の出現回数が、ここで指定した回数に満たない単語を除外する\n",
        "#  epochs: 学習回数\n",
        "#  workers: 学習実行に使用するスレッド数\n",
        "model = Doc2Vec(documents=title_words_lists, vector_size=10, window=3, min_count=1, epochs=5, workers=6)\n",
        "\n",
        "# 学習結果を保存(学習には時間がかかることがあるため)\n",
        "model.save('test.model')\n",
        "\n",
        "# 学習結果を使用して、テスト用データをベクトル化\n",
        "vector = model.infer_vector(title_words_lists_test[0].words)\n",
        "\n",
        "# ベクトル化したテスト用データに対して、学習用データから類似するものを表示\n",
        "similar_texts = model.docvecs.most_similar([vector])\n",
        "print('===テスト用データに類似する文書===')\n",
        "print('(タイトル, 近似スコア)')\n",
        "print('------')\n",
        "for similar_text in similar_texts:\n",
        "  print(similar_text)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===テスト用データに類似する文書===\n",
            "(タイトル, 近似スコア)\n",
            "------\n",
            "('おにぎり', 0.10985822230577469)\n",
            "('うどん', -0.08030092716217041)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5tPcjp1WJk2",
        "colab_type": "text"
      },
      "source": [
        "学習はランダム要素があるため、同じコードを使っても近似スコアが異なる。    \n",
        "類似度のチューニングについては、Doc2Vec関数の引数を調整することで実施できる可能性がある。  \n",
        "ただし、どの引数を調整してどのように結果が変化するかは試してみないとわからない。  \n",
        "インプットするデータをきれいにする方がうまくいくこともある。"
      ]
    }
  ]
}